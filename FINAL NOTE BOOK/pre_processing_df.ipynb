{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_Ocqn9EULeA",
        "outputId": "36412311-380f-433d-cf89-59a072af2bc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import spacy\n",
        "import io\n",
        "from spacy.matcher import Matcher\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import subprocess\n",
        "import constants as cs\n",
        "import docxpy\n",
        "import glob\n",
        "import numpy as np\n",
        "# load pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dspp0g1GnjSQ",
        "outputId": "b70e3205-588e-4e92-e783-777cd9a92346"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install constants"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5nrt6ZTnsjs",
        "outputId": "d32bcc82-f262-4ae5-a260-400910717398"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: constants in /usr/local/lib/python3.10/dist-packages (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install docxpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlD1VUW6nulb",
        "outputId": "de931829-c30b-4783-d1ca-3bc293848896"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: docxpy in /usr/local/lib/python3.10/dist-packages (0.8.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install docx2txt "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDA39tIjnypT",
        "outputId": "49474a0a-3599-4c3b-e509-b741dd1b35c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.10/dist-packages (0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vXs-LX-xM8v",
        "outputId": "3c3bec13-ffc6-4583-df75-548cc496377f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (0.8.11)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx2txt"
      ],
      "metadata": {
        "id": "43BaArlQn1SD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run constants.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ELR4DQ7n4Rr",
        "outputId": "7c718a0b-63c1-41ec-dc5d-f5c79e1edacb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2Mm-6-IoCoy",
        "outputId": "4d856e3c-17cd-4f9a-e237-cec1c457c2d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'constants' from '/content/constants.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# FOR INDIAN RESUME RUN THE BELOW FUNCTION TO EXTRACT MOBILE NUMBER\n",
        "def extract_mobile_number(text):\n",
        "    phone= re.findall(r'[8-9]{1}[0-9]{9}',text)\n",
        "    \n",
        "    if len(phone) > 10:\n",
        "        return '+' + phone\n",
        "    else:\n",
        "        return phone\n",
        "\n",
        "def extract_email(text):\n",
        "        email = re.findall(\"([^@|\\s]+@[^@]+\\.[^@|\\s]+)\", text)\n",
        "        if email:\n",
        "            try:\n",
        "                return email[0].split()[0].strip(';')\n",
        "            except IndexError:\n",
        "                return None\n",
        "\n",
        "# Function to remove punctuation and tokenize the text\n",
        "def tokenText(extText):\n",
        "   \n",
        "    # Remove punctuation marks\n",
        "    punc = '''!()-[]{};:'\"\\,.<>/?@#$%^&*_~'''\n",
        "    for ele in extText:\n",
        "        if ele in punc:\n",
        "            puncText = extText.replace(ele, \"\")\n",
        "            \n",
        "    # Tokenize the text and remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    puncText.split()\n",
        "    word_tokens = word_tokenize(puncText)\n",
        "    TokenizedText = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "    TokenizedText = []\n",
        "  \n",
        "    for w in word_tokens:\n",
        "        if w not in stop_words:\n",
        "            TokenizedText.append(w)\n",
        "    return(TokenizedText)            \n",
        "\n",
        "# Function to extract Name and contact details\n",
        "def extract_name(Text):\n",
        "    name = ''  \n",
        "    for i in range(0,3):\n",
        "        name = \" \".join([name, Text[i]])\n",
        "    return(name)\n",
        "\n",
        "# Grad all general stop words\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "# Education Degrees\n",
        "EDUCATION = ['BE','B.E.', 'B.E', 'BS','B.S','B.Com','BCA','ME','M.E', 'M.E.', 'M.S','B.com','10','10+2','BTECH', 'B.TECH', 'M.TECH', 'MTECH', 'SSC', 'HSC', 'C.B.S.E','CBSE','ICSE', 'X', 'XII','10th','12th',' 10th',' 12th','Bachelor of Arts in Mathematics','Master of Science in Analytics','Bachelor of Business Administration','Major: Business Management']\n",
        "\n",
        "def extract_education(text):\n",
        "    nlp_text = nlp(text)\n",
        "\n",
        "    # Sentence Tokenizer\n",
        "    nlp_text = [sent.text.strip() for sent in nlp_text.sents]\n",
        "\n",
        "\n",
        "    edu = {}\n",
        "    # Extract education degree\n",
        "    for index, t in enumerate(nlp_text):\n",
        "        for tex in t.split():\n",
        "            # Replace all special symbols\n",
        "            tex = re.sub(r'[?|$|.|!|,]', r'', tex)\n",
        "            if tex in EDUCATION and tex not in STOPWORDS:\n",
        "                edu[tex] = t + nlp_text[index + 1]\n",
        "\n",
        "    # Extract year\n",
        "    education = []\n",
        "    for key in edu.keys():\n",
        "        year = re.search(re.compile(r'(((20|19)(\\d{2})))'), edu[key])\n",
        "        if year:\n",
        "            education.append((key, ''.join(year[0])))\n",
        "        else:\n",
        "            education.append(key)\n",
        "    return education\n",
        "\n",
        "def extract_skills(resume_text):\n",
        "\n",
        "        nlp_text = nlp(resume_text)\n",
        "        noun_chunks = nlp_text.noun_chunks\n",
        "\n",
        "        # removing stop words and implementing word tokenization\n",
        "        tokens = [token.text for token in nlp_text if not token.is_stop]\n",
        "        \n",
        "        # reading the csv file\n",
        "        data = pd.read_csv(\"skills.csv\") \n",
        "        \n",
        "        # extract values\n",
        "        skills = list(data.columns.values)\n",
        "        \n",
        "        skillset = []\n",
        "        \n",
        "        # check for one-grams (example: python)\n",
        "        for token in tokens:\n",
        "            if token.lower() in skills:\n",
        "                skillset.append(token)\n",
        "        \n",
        "        # check for bi-grams and tri-grams (example: machine learning)\n",
        "        for token in noun_chunks:\n",
        "            token = token.text.lower().strip()\n",
        "            if token in skills:\n",
        "                skillset.append(token)\n",
        "        \n",
        "        return [i.capitalize() for i in set([i.lower() for i in skillset])]\n",
        "\n",
        "\n",
        "\n",
        "def string_found(string1, string2):\n",
        "        if re.search(r\"\\b\" + re.escape(string1) + r\"\\b\", string2):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "def extract_entity_sections_grad(text):\n",
        "    '''\n",
        "    Helper function to extract all the raw text from sections of resume specifically for \n",
        "    graduates and undergraduates\n",
        "    :param text: Raw text of resume\n",
        "    :return: dictionary of entities\n",
        "    '''\n",
        "    text_split = [i.strip() for i in text.split('\\n')]\n",
        "    entities = {}\n",
        "    key = False\n",
        "    for phrase in text_split:\n",
        "        if len(phrase) == 1:\n",
        "            p_key = phrase\n",
        "        else:\n",
        "            p_key = set(phrase.lower().split()) & set(cs.RESUME_SECTIONS_GRAD)\n",
        "        try:\n",
        "            p_key = list(p_key)[0]\n",
        "        except IndexError:\n",
        "            pass\n",
        "        if p_key in cs.RESUME_SECTIONS_GRAD:\n",
        "            entities[p_key] = []\n",
        "            key = p_key\n",
        "        elif key and phrase.strip():\n",
        "            entities[key].append(phrase)\n",
        "    return entities \n",
        "\n",
        "# Function to extract experience details\n",
        "def expDetails(Text):\n",
        "    global sent\n",
        "   \n",
        "    Text = Text.split()\n",
        "   \n",
        "    for i in range(len(Text)-2):\n",
        "        Text[i].lower()\n",
        "        \n",
        "        if Text[i] ==  'years':\n",
        "            sent =  Text[i-2] + ' ' + Text[i-1] +' ' + Text[i] +' '+ Text[i+1] +' ' + Text[i+2]\n",
        "            l = re.findall('\\d*\\.?\\d+',sent)\n",
        "            for i in l:\n",
        "                a = float(i)\n",
        "            return(a)\n",
        "            return (sent)\n",
        "\n",
        "def extract_experience(resume_text):\n",
        "    '''\n",
        "    Helper function to extract experience from resume text\n",
        "    :param resume_text: Plain resume text\n",
        "    :return: list of experience\n",
        "    '''\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # word tokenization \n",
        "    word_tokens = nltk.word_tokenize(resume_text)\n",
        "\n",
        "    # remove stop words and lemmatize  \n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words and wordnet_lemmatizer.lemmatize(w) not in stop_words] \n",
        "    sent = nltk.pos_tag(filtered_sentence)\n",
        "\n",
        "    # parse regex\n",
        "    cp = nltk.RegexpParser('P: {<NNP>+}')\n",
        "    cs = cp.parse(sent)\n",
        "    \n",
        "    # for i in cs.subtrees(filter=lambda x: x.label() == 'P'):\n",
        "    #     print(i)\n",
        "    \n",
        "    test = []\n",
        "    \n",
        "    for vp in list(cs.subtrees(filter=lambda x: x.label()=='P')):\n",
        "        test.append(\" \".join([i[0] for i in vp.leaves() if len(vp.leaves()) >= 2]))\n",
        "\n",
        "    # Search the word 'experience' in the chunk and then print out the text after it\n",
        "    x = [x[x.lower().index('experience') + 10:] for i, x in enumerate(test) if x and 'experience' in x.lower()]\n",
        "    return x\n",
        "\n",
        "def string_found(string1, string2):\n",
        "        if re.search(r\"\\b\" + re.escape(string1) + r\"\\b\", string2):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "def get_score(_dict):\n",
        "    _len = len(_dict)\n",
        "    if _len >= 5:\n",
        "        return 1\n",
        "    elif _len < 5 and _len > 2:\n",
        "        return 0.5\n",
        "    elif _len  == 1:\n",
        "        return 0.2\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def extract_competencies(text, experience_list):\n",
        "    '''\n",
        "    Helper function to extract competencies from resume text\n",
        "    :param resume_text: Plain resume text\n",
        "    :return: dictionary of competencies\n",
        "    '''\n",
        "    experience_text = ' '.join(experience_list)\n",
        "    competency_dict = {}\n",
        "    score = 0\n",
        "\n",
        "    percentage = (100 // len(cs.COMPETENCIES.keys()))\n",
        "\n",
        "    for competency in cs.COMPETENCIES.keys():\n",
        "        matches = {}\n",
        "        for item in cs.COMPETENCIES[competency]:\n",
        "            if string_found(item, experience_text):\n",
        "                if competency not in competency_dict.keys():\n",
        "                    match = re.search(r'([^.|,]*' + item + '[^.|,]*)', experience_text)\n",
        "                    if item not in matches.keys():\n",
        "                        matches[item] = [match.group(0)]\n",
        "                    else:\n",
        "                        for i in match.groups():\n",
        "                            matches[item].append(i)    \n",
        "                    competency_dict[competency] = matches\n",
        "                else:\n",
        "                    match = re.search(r'([^.|,]*' + item + '[^.|,]*)', experience_text)\n",
        "                    if item not in matches.keys():\n",
        "                        matches[item] = [match.group(0)]\n",
        "                    else:\n",
        "                        for i in match.groups():\n",
        "                            matches[item].append(i)\n",
        "                    competency_dict[competency] = matches\n",
        "                score += get_score(competency_dict[competency]) * percentage\n",
        "    \n",
        "    competency_dict['score'] = score \n",
        "    list=list(competency_dict.keys())\n",
        "    return(list)\n",
        "\n",
        "def extract_competencies_score(text, experience_list):\n",
        "        '''\n",
        "        Helper function to extract competencies from resume text\n",
        "        :param resume_text: Plain resume text\n",
        "        :return: dictionary of competencies\n",
        "        '''\n",
        "        experience_text = ' '.join(experience_list)\n",
        "        competency_dict = {}\n",
        "        score = 0\n",
        "\n",
        "        percentage = (100 // len(cs.COMPETENCIES.keys()))\n",
        "\n",
        "        for competency in cs.COMPETENCIES.keys():\n",
        "            matches = {}\n",
        "            for item in cs.COMPETENCIES[competency]:\n",
        "                if string_found(item, experience_text):\n",
        "                    if competency not in competency_dict.keys():\n",
        "                        match = re.search(r'([^.|,]*' + item + '[^.|,]*)', experience_text)\n",
        "                        if item not in matches.keys():\n",
        "                            matches[item] = [match.group(0)]\n",
        "                        else:\n",
        "                            for i in match.groups():\n",
        "                                matches[item].append(i)    \n",
        "                        competency_dict[competency] = matches\n",
        "                    else:\n",
        "                        match = re.search(r'([^.|,]*' + item + '[^.|,]*)', experience_text)\n",
        "                        if item not in matches.keys():\n",
        "                            matches[item] = [match.group(0)]\n",
        "                        else:\n",
        "                            for i in match.groups():\n",
        "                                matches[item].append(i)\n",
        "                        competency_dict[competency] = matches\n",
        "                    score += get_score(competency_dict[competency]) * percentage\n",
        "        \n",
        "        competency_dict['score'] = score \n",
        "        return(competency_dict['score'])\n",
        "\n",
        "def extract_dob(text):\n",
        "        \n",
        "    result1=re.findall(r\"[\\d]{1,2}/[\\d]{1,2}/[\\d]{4}\",text)\n",
        "    result2=re.findall(r\"[\\d]{1,2}-[\\d]{1,2}-[\\d]{4}\",text)           \n",
        "    result3= re.findall(r\"[\\d]{1,2} [ADFJMNOSadfjmnos]\\w* [\\d]{4}\",text)\n",
        "    result4=re.findall(r\"([\\d]{1,2})\\.([\\d]{1,2})\\.([\\d]{4})\",text)\n",
        "                \n",
        "    l=[result1,result2,result3,result4]\n",
        "    for i in l:\n",
        "        if i==[]:\n",
        "            continue\n",
        "        else:\n",
        "            return i\n",
        "\n",
        "\n",
        "def extract_text_from_docx(path):\n",
        "    '''\n",
        "    Helper function to extract plain text from .docx files\n",
        "    :param doc_path: path to .docx file to be extracted\n",
        "    :return: string of extracted text\n",
        "    '''\n",
        "    try:\n",
        "        temp = docx2txt.process(path)\n",
        "        return temp\n",
        "    except KeyError:\n",
        "        return ' '\n",
        "\n"
      ],
      "metadata": {
        "id": "HcjjY7uUoO-S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_doc(path):\n",
        "    '''\n",
        "    Helper function to extract plain text from .docx files\n",
        "    :param doc_path: path to .docx file to be extracted\n",
        "    :return: string of extracted text\n",
        "    '''\n",
        "    try:\n",
        "        temp = doc2txt.process(path)\n",
        "        return temp\n",
        "    except KeyError:\n",
        "        return ' '"
      ],
      "metadata": {
        "id": "YQlJoo4Nz9eg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(path):\n",
        "    '''\n",
        "    Helper function to extract plain text from .docx files\n",
        "    :param doc_path: path to .docx file to be extracted\n",
        "    :return: string of extracted text\n",
        "    '''\n",
        "    try:\n",
        "        temp = pdf2txt.process(path)\n",
        "        return temp\n",
        "    except KeyError:\n",
        "        return ' '"
      ],
      "metadata": {
        "id": "OT4T-ldXz_WJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns=['Name','Mobile No.', 'Email','DOB','Education Qualifications','Skills','Experience (Years)','Last Position','Competence','competence score'], dtype=object)"
      ],
      "metadata": {
        "id": "7CcTYxsKoR7S"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "path_input = r\"/content/Peoplesoft Admin_AnubhavSingh.docx\"\n",
        "if path_input.endswith('.docx'):\n",
        "    text = extract_text_from_docx(path_input)\n",
        "    tokText = tokenText(text)\n",
        "    df.loc[i,'Name']=extract_name(tokText)\n",
        "    df.loc[i,'Mobile No.']=extract_mobile_number(text)\n",
        "    df.loc[i,'Email']=extract_email(text)\n",
        "    df.loc[i,'DOB']=extract_dob(text)\n",
        "    df.loc[i,'Education Qualifications']=extract_education(text)\n",
        "    df.loc[i,'Skills']=extract_skills(text)\n",
        "    df.loc[i,'Experience (Years)']=expDetails(text) \n",
        "    experience_list1=extract_entity_sections_grad(text) \n",
        "\n",
        "    if 'experience' in experience_list1:\n",
        "        i=0\n",
        "        experience_list=experience_list1['experience']\n",
        "        df.loc[i,'Last Position']=extract_experience(text)\n",
        "        df.loc[i,'competence score']=extract_competencies_score(text,experience_list)\n",
        "\n",
        "    else:\n",
        "        df.loc[i,'Last Position']='NA'\n",
        "        df.loc[i,'Competence']='NA'\n",
        "        df.loc[i,'competence score']='NA'\n",
        "    i+=1"
      ],
      "metadata": {
        "id": "otlhjQyCuAFh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "gnKQ8tMUuNvK",
        "outputId": "9043717a-a9dc-46fe-b0aa-7474925eb722"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Name Mobile No. Email           DOB  \\\n",
              "0   Anubhav Kumar Singh         []  None  [11/09/1990]   \n",
              "\n",
              "  Education Qualifications                                             Skills  \\\n",
              "0                       []  [Certification, Github, Migration, Unix, Shell...   \n",
              "\n",
              "  Experience (Years)                             Last Position Competence  \\\n",
              "0               None  [,  Installing Oracle Policy Automation]        NaN   \n",
              "\n",
              "  competence score  \n",
              "0              8.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-162e0133-287c-49e8-ba18-b7cb9b56f3ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Mobile No.</th>\n",
              "      <th>Email</th>\n",
              "      <th>DOB</th>\n",
              "      <th>Education Qualifications</th>\n",
              "      <th>Skills</th>\n",
              "      <th>Experience (Years)</th>\n",
              "      <th>Last Position</th>\n",
              "      <th>Competence</th>\n",
              "      <th>competence score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Anubhav Kumar Singh</td>\n",
              "      <td>[]</td>\n",
              "      <td>None</td>\n",
              "      <td>[11/09/1990]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[Certification, Github, Migration, Unix, Shell...</td>\n",
              "      <td>None</td>\n",
              "      <td>[,  Installing Oracle Policy Automation]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-162e0133-287c-49e8-ba18-b7cb9b56f3ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-162e0133-287c-49e8-ba18-b7cb9b56f3ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-162e0133-287c-49e8-ba18-b7cb9b56f3ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjoJRzlyI8b8",
        "outputId": "85715d80-8a5d-43d9-c9ea-a2ad99657c3d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textract in /usr/local/lib/python3.10/dist-packages (1.6.5)\n",
            "Requirement already satisfied: argcomplete~=1.10.0 in /usr/local/lib/python3.10/dist-packages (from textract) (1.10.3)\n",
            "Requirement already satisfied: beautifulsoup4~=4.8.0 in /usr/local/lib/python3.10/dist-packages (from textract) (4.8.2)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from textract) (3.0.4)\n",
            "Requirement already satisfied: docx2txt~=0.8 in /usr/local/lib/python3.10/dist-packages (from textract) (0.8)\n",
            "Requirement already satisfied: extract-msg<=0.29.* in /usr/local/lib/python3.10/dist-packages (from textract) (0.28.7)\n",
            "Collecting pdfminer.six==20191110 (from textract)\n",
            "  Using cached pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
            "Requirement already satisfied: python-pptx~=0.6.18 in /usr/local/lib/python3.10/dist-packages (from textract) (0.6.21)\n",
            "Requirement already satisfied: six~=1.12.0 in /usr/local/lib/python3.10/dist-packages (from textract) (1.12.0)\n",
            "Requirement already satisfied: SpeechRecognition~=3.8.1 in /usr/local/lib/python3.10/dist-packages (from textract) (3.8.1)\n",
            "Requirement already satisfied: xlrd~=1.2.0 in /usr/local/lib/python3.10/dist-packages (from textract) (1.2.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20191110->textract) (3.18.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.8.0->textract) (2.4.1)\n",
            "Requirement already satisfied: imapclient==2.1.0 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (2.1.0)\n",
            "Requirement already satisfied: olefile>=0.46 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (0.46)\n",
            "Requirement already satisfied: tzlocal>=2.1 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (4.3)\n",
            "Requirement already satisfied: compressed-rtf>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (1.0.6)\n",
            "Requirement already satisfied: ebcdic>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (1.1.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (4.9.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (9.5.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (3.1.2)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal>=2.1->extract-msg<=0.29.*->textract) (0.1.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal>=2.1->extract-msg<=0.29.*->textract) (2023.3)\n",
            "Installing collected packages: pdfminer.six\n",
            "  Attempting uninstall: pdfminer.six\n",
            "    Found existing installation: pdfminer.six 20221105\n",
            "    Uninstalling pdfminer.six-20221105:\n",
            "      Successfully uninstalled pdfminer.six-20221105\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pdfplumber 0.9.0 requires pdfminer.six==20221105, but you have pdfminer-six 20191110 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pdfminer.six-20191110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIfIFjm5JK9U",
        "outputId": "ee62d0d7-9ea0-4080-e5fb-1d972f72c281"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Collecting pdfminer.six==20221105 (from pdfplumber)\n",
            "  Using cached pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.5.0)\n",
            "Requirement already satisfied: Wand>=0.6.10 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (0.6.11)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (2.0.12)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (40.0.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n",
            "Installing collected packages: pdfminer.six\n",
            "  Attempting uninstall: pdfminer.six\n",
            "    Found existing installation: pdfminer.six 20191110\n",
            "    Uninstalling pdfminer.six-20191110:\n",
            "      Successfully uninstalled pdfminer.six-20191110\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "textract 1.6.5 requires pdfminer.six==20191110, but you have pdfminer-six 20221105 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pdfminer.six-20221105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "def extract_text_from_docx(file_path):\n",
        "    doc = Document(file_path)\n",
        "    paragraphs = [p.text for p in doc.paragraphs]\n",
        "    return '\\n'.join(paragraphs)"
      ],
      "metadata": {
        "id": "N0G6Qj_BI-2E"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        text = ''\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text()\n",
        "        return text\n",
        "\n",
        "# Rest of the code remains the same\n"
      ],
      "metadata": {
        "id": "OZqQe4-ZJA_7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hn1zB9QJWM9",
        "outputId": "58435df8-be18-44dd-d16e-07e0828e96cc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfFileReader(file)\n",
        "        num_pages = reader.numPages\n",
        "        text = ''\n",
        "        for page in range(num_pages):\n",
        "            text += reader.getPage(page).extractText()\n",
        "        return text"
      ],
      "metadata": {
        "id": "Boxpt6roJXxk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from docx import Document\n",
        "\n",
        "def extract_text_from_docx(file_path):\n",
        "    document = Document(file_path)\n",
        "    paragraphs = [p.text for p in document.paragraphs]\n",
        "    return '\\n'.join(paragraphs)\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    # Code to extract text from PDF goes here\n",
        "    # Replace this with your own implementation or use a library like PyPDF2 or pdfminer\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(columns=['Name', 'Mobile No.', 'Email', 'DOB', 'Education Qualifications', 'Skills',\n",
        "                               'Experience (Years)', 'Last Position', 'Competence', 'competence score'])"
      ],
      "metadata": {
        "id": "c8COoW9OLZiO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install docx2txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN_yx4aybdlB",
        "outputId": "814d9132-02c2-4d2d-849f-66f9fb04d35f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.10/dist-packages (0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx2txt"
      ],
      "metadata": {
        "id": "18SucQf2b5CA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "def extract_text_from_docx(file_path):\n",
        "    doc = Document(file_path)\n",
        "    paragraphs = [p.text for p in doc.paragraphs]\n",
        "    return \"\\n\".join(paragraphs)\n"
      ],
      "metadata": {
        "id": "66lIYz3VdzTf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "def extract_text_from_doc(file_path):\n",
        "    process = subprocess.Popen(['antiword', file_path], stdout=subprocess.PIPE)\n",
        "    output, _ = process.communicate()\n",
        "    return output.decode('utf-8')\n"
      ],
      "metadata": {
        "id": "JJGnHQYkd2-H"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "Rt7rcfLhd4fO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import docx2txt\n",
        "\n",
        "def extract_text_from_doc(file_path):\n",
        "    text = docx2txt.process(file_path)\n",
        "    return text"
      ],
      "metadata": {
        "id": "mIn4Z2xaeBR-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inKi7K94-aMc",
        "outputId": "deeb5955-bf8c-42dd-d727-36b5d1e7c049"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D56jzfBA-1Jp",
        "outputId": "12a8e3d1-56c5-4bc2-8c4a-590e5df0fa26"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWsb3NDR_Qh-",
        "outputId": "95a10dd2-c32d-4933-cc6e-e6eee14abf73"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pdfplumber\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pdfplumber/cli.py\", line 61, in main\n",
            "    with PDF.open(args.infile, pages=args.pages, laparams=args.laparams) as pdf:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pdfplumber/pdf.py\", line 78, in open\n",
            "    return cls(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pdfplumber/pdf.py\", line 40, in __init__\n",
            "    self.doc = PDFDocument(PDFParser(stream), password=password)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pdfminer/pdfparser.py\", line 46, in __init__\n",
            "    PSStackParser.__init__(self, fp)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pdfminer/psparser.py\", line 545, in __init__\n",
            "    PSBaseParser.__init__(self, fp)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pdfminer/psparser.py\", line 193, in __init__\n",
            "    self.seek(0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pdfminer/psparser.py\", line 557, in seek\n",
            "    PSBaseParser.seek(self, pos)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pdfminer/psparser.py\", line 220, in seek\n",
            "    self.fp.seek(pos)\n",
            "io.UnsupportedOperation: File or stream is not seekable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import docx\n",
        "\n",
        "# Folder path containing the files\n",
        "folder_path = r\"/content/drive/MyDrive/Resumes\"\n",
        "\n",
        "# File extensions to consider\n",
        "file_extensions = ['pdf', 'docx', 'doc']\n",
        "\n",
        "# Initialize an empty DataFrame\n",
        "df = pd.DataFrame(columns=['Name', 'Mobile No.', 'Email', 'DOB', 'Education Qualifications',\n",
        "                           'Skills', 'Experience (Years)', 'Last Position', 'Competence',\n",
        "                           'competence score'])\n",
        "\n",
        "# Retrieve file paths matching the extensions\n",
        "file_paths = []\n",
        "for ext in file_extensions:\n",
        "    file_paths.extend(glob.glob(os.path.join(folder_path, f\"*.{ext}\")))\n",
        "\n",
        "# Process each file\n",
        "for i, path_input in enumerate(file_paths):\n",
        "    try:\n",
        "        if path_input.endswith('.docx'):\n",
        "            # Process DOCX files\n",
        "            doc = docx.Document(path_input)\n",
        "            paragraphs = [p.text for p in doc.paragraphs]\n",
        "            text = \"\\n\".join(paragraphs)\n",
        "        elif path_input.endswith('.doc'):\n",
        "            # Process DOC files\n",
        "            doc = docx.Document(path_input)\n",
        "            paragraphs = [p.text for p in doc.paragraphs]\n",
        "            text = \"\\n\".join(paragraphs)\n",
        "        elif path_input.endswith('.pdf'):\n",
        "            # Process PDF files\n",
        "            text = extract_text_from_pdf(path_input)\n",
        "        else:\n",
        "            # Skip unsupported file formats\n",
        "            continue\n",
        "\n",
        "        tokText = tokenText(text)\n",
        "        df.loc[i, 'Name'] = extract_name(tokText)\n",
        "        df.loc[i, 'Mobile No.'] = extract_mobile_number(text)\n",
        "        df.loc[i, 'Email'] = extract_email(text)\n",
        "        df.loc[i, 'DOB'] = extract_dob(text)\n",
        "        df.loc[i, 'Education Qualifications'] = extract_education(text)\n",
        "        df.loc[i, 'Skills'] = extract_skills(text)\n",
        "        df.loc[i, 'Experience (Years)'] = expDetails(text)\n",
        "        experience_list1 = extract_entity_sections_grad(text)\n",
        "\n",
        "        if 'experience' in experience_list1:\n",
        "            experience_list = experience_list1['experience']\n",
        "            df.loc[i, 'Last Position'] = extract_experience(text)\n",
        "           \n",
        "            df.loc[i, 'competence score'] = extract_competencies_score(text, experience_list)\n",
        "        else:\n",
        "            df.loc[i, 'Last Position'] = 'NA'\n",
        "            df.loc[i, 'Competence'] = 'NA'\n",
        "            df.loc[i, 'competence score'] = 'NA'\n",
        "\n",
        "    except ValueError as e:\n",
        "        if \"file is not a Word file\" in str(e):\n",
        "            # Skip files that are not valid Word files\n",
        "            print(f\"Skipped file: {path_input} - Not a valid Word file\")\n",
        "        else:\n",
        "            # Handle other ValueErrors\n",
        "            print(f\"Error processing file: {path_input} - {str(e)}\")\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWKaKLZO9mg8",
        "outputId": "739b9472-aef0-49b5-d4d9-30858565f185"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing file: /content/drive/MyDrive/Resumes/React Developer_PavasGoswami.doc - file '/content/drive/MyDrive/Resumes/React Developer_PavasGoswami.doc' is not a Word file, content type is 'application/vnd.openxmlformats-officedocument.themeManager+xml'\n",
            "Error processing file: /content/drive/MyDrive/Resumes/React Developer_Vinay Reddy.doc - file '/content/drive/MyDrive/Resumes/React Developer_Vinay Reddy.doc' is not a Word file, content type is 'application/vnd.openxmlformats-officedocument.themeManager+xml'\n",
            "Error processing file: /content/drive/MyDrive/Resumes/React JS Developer_AnjaniPriyadarshini.doc - file '/content/drive/MyDrive/Resumes/React JS Developer_AnjaniPriyadarshini.doc' is not a Word file, content type is 'application/vnd.openxmlformats-officedocument.themeManager+xml'\n",
            "                                  Name    Mobile No.  \\\n",
            "0                             Page | 1            []   \n",
            "1                        Name Ravali P            []   \n",
            "2                  SUSOVAN BAG Seeking            []   \n",
            "3    Venkatalakshmi Pedireddy Software            []   \n",
            "4                Kanumuru Deepak Reddy            []   \n",
            "5                 KAMBALA SAI SURENDRA            []   \n",
            "6               Ui-Developer/ React JS            []   \n",
            "7           PRAGNYA PATTNAIK Expertise            []   \n",
            "8         HARIPRIYA BATTINA Experience  [9908576950]   \n",
            "9                   Naveen Sadhu Title            []   \n",
            "10                   KAMALAKAR REDDY .            []   \n",
            "11                 MAREEDU LOKESH BABU            []   \n",
            "12                              204 ,            []   \n",
            "13                 Kotani Durga Prasad            []   \n",
            "14         Thirupathamma Balla SUMMARY            []   \n",
            "15                 MAREEDU LOKESH BABU            []   \n",
            "16              Ui-Developer/ React JS            []   \n",
            "17                  SHAIK ABDUL SHARUK            []   \n",
            "18                 MD KHIZARUDDIN RAUF            []   \n",
            "19                Ranga Gaganam Having            []   \n",
            "20               Pranish Sonone Career            []   \n",
            "\n",
            "                        Email           DOB Education Qualifications  \\\n",
            "0                        None  [23/01/1995]                       []   \n",
            "1                        None  [04/11/1995]                     [BE]   \n",
            "2                        None          None                       []   \n",
            "3                        None          None            [(SSC, 2018)]   \n",
            "4                        None          None             [(10, 1997)]   \n",
            "5                        None          None                       []   \n",
            "6                        None          None                       []   \n",
            "7                        None          None                     [10]   \n",
            "8   haripriyabattini@gmai.com          None            [(SSC, 2012)]   \n",
            "9                        None          None                       []   \n",
            "10                       None          None                       []   \n",
            "11                       None          None                       []   \n",
            "12                       None          None                       []   \n",
            "13                       None          None                       []   \n",
            "14                       None          None                       []   \n",
            "15                       None          None                       []   \n",
            "16                       None          None                       []   \n",
            "17   sharukabdul786@gmail.com          None                       []   \n",
            "18                       None   [1-06-1998]                     [10]   \n",
            "19                       None          None                       []   \n",
            "20                       None          None                       []   \n",
            "\n",
            "                                               Skills Experience (Years)  \\\n",
            "0   [Design, Queries, Aws, Js, Analytical, Unix, U...                2.4   \n",
            "1   [Technical, Sdlc, Test cases, Security, Plan, ...               None   \n",
            "2   [Routing, Networking, Css, System, Administrat...               None   \n",
            "3   [Sales, Website, Js, Payments, Warehouse, Engi...               None   \n",
            "4   [Js, Apis, Ui, Routing, System, Css, Testing, ...                2.0   \n",
            "5   [Technical, Visual, Js, Javascript, Presentati...               None   \n",
            "6   [Js, Github, Ui, Css, System, Json, Website, A...                3.2   \n",
            "7   [Js, Analytical, Ui, Consulting, System, Css, ...                2.0   \n",
            "8   [Js, Ui, Information technology, Css, System, ...               None   \n",
            "9   [Analytical, Html, Engineering, Css, Communica...               None   \n",
            "10  [Js, Ui, System, Css, Content, Data collection...                3.0   \n",
            "11  [Construction, Js, Analytical, Servers, Css, S...                2.0   \n",
            "12  [Design, Js, Javascript, Architecture, Ui, Deb...                3.0   \n",
            "13  [Queries, Js, Ui, Routing, Os, Mobile, Json, V...                3.1   \n",
            "14  [Technical, Json, Analytical, Javascript, Prog...               None   \n",
            "15  [Construction, Js, Analytical, Servers, Css, S...                2.0   \n",
            "16  [Js, Github, Ui, Css, System, Json, Website, A...                3.2   \n",
            "17            [Technical, Js, Github, Email, English]               None   \n",
            "18  [Design, Improvement, Js, Analytical, Javascri...               None   \n",
            "19  [Design, Sdlc, Software development life cycle...                1.0   \n",
            "20  [Design, Technical, Ecommerce, Js, Javascript,...                2.0   \n",
            "\n",
            "                                        Last Position Competence  \\\n",
            "0                                                  []        NaN   \n",
            "1                                                  NA         NA   \n",
            "2                                                  NA         NA   \n",
            "3     [,  Developer Schemax Expert Techno Crafts Pvt]        NaN   \n",
            "4                                              [ DOM]        NaN   \n",
            "5                                                  NA         NA   \n",
            "6      [ React JS Software Developer, d React JS, , ]        NaN   \n",
            "7                                                  []        NaN   \n",
            "8                 [ UI Developer Reactjs,  EDUCATION]        NaN   \n",
            "9                           [ Current Project Client]        NaN   \n",
            "10                             [ Development,  MARCH]        NaN   \n",
            "11                                                 []        NaN   \n",
            "12                                                 NA         NA   \n",
            "13                                                 []        NaN   \n",
            "14  [ Object Oriented Programming,  Work Experienc...        NaN   \n",
            "15                                                 []        NaN   \n",
            "16     [ React JS Software Developer, d React JS, , ]        NaN   \n",
            "17                          [ Wipro Career Objective]        NaN   \n",
            "18               [  Currently, :9 Months Internship]        NaN   \n",
            "19                                                 []        NaN   \n",
            "20                                                 []        NaN   \n",
            "\n",
            "   competence score  \n",
            "0               4.0  \n",
            "1                NA  \n",
            "2                NA  \n",
            "3                 0  \n",
            "4              16.0  \n",
            "5                NA  \n",
            "6               4.0  \n",
            "7               8.0  \n",
            "8                 0  \n",
            "9               8.0  \n",
            "10                0  \n",
            "11              4.0  \n",
            "12               NA  \n",
            "13                0  \n",
            "14                0  \n",
            "15              4.0  \n",
            "16              4.0  \n",
            "17                0  \n",
            "18                0  \n",
            "19              4.0  \n",
            "20              8.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the data is stored in a variable called 'df'\n",
        "data_str = df.to_string(index=False)\n",
        "\n",
        "# Print the data string\n",
        "print(data_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycRC0gyNEXgy",
        "outputId": "3d11a9fd-ef02-426d-f494-cbbe28416f36"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              Name   Mobile No.                     Email          DOB Education Qualifications                                                                                                                                                                                                                                                           Skills Experience (Years)                                                     Last Position Competence competence score\n",
            "                          Page | 1           []                      None [23/01/1995]                       []                                                                                                                              [Design, Queries, Aws, Js, Analytical, Unix, Ui, Api, Android, Pattern, Xml, Windows, Css, System, Mobile, Programming, Html, Java]                2.4                                                                []        NaN              4.0\n",
            "                     Name Ravali P           []                      None [04/11/1995]                     [BE]                                                                                                                            [Technical, Sdlc, Test cases, Security, Plan, Usability, P, System, Agile, Scrum, English, Computer science, Testing, Training, Java]               None                                                                NA         NA               NA\n",
            "               SUSOVAN BAG Seeking           []                      None         None                       []                                                                      [Routing, Networking, Css, System, Administration, Os, Linux, Website, Communication, Sql, Troubleshooting, Engineering, Algorithms, Programming, Javascript, Api, Android, Hotel, Html, C]               None                                                                NA         NA               NA\n",
            " Venkatalakshmi Pedireddy Software           []                      None         None            [(SSC, 2018)]                                                                                                                                                      [Sales, Website, Js, Payments, Warehouse, Engineering, System, Erp, Procurement, English, Logistics, Mysql]               None                   [,  Developer Schemax Expert Techno Crafts Pvt]        NaN                0\n",
            "             Kanumuru Deepak Reddy           []                      None         None             [(10, 1997)]                                                  [Js, Apis, Ui, Routing, System, Css, Testing, Json, Visual, Website, Windows, Communication, English, Analysis, Design, Technical, Software development life cycle, Fabric, Sdlc, Javascript, Api, Html5, Html]                2.0                                                            [ DOM]        NaN             16.0\n",
            "              KAMBALA SAI SURENDRA           []                      None         None                       []                                                                                                                                               [Technical, Visual, Js, Javascript, Presentation, Windows, Engineering, Css, System, Computer science, Html, Java]               None                                                                NA         NA               NA\n",
            "            Ui-Developer/ React JS           []                      None         None                       []                                               [Js, Github, Ui, Css, System, Json, Website, Architecture, Video, Scrum, Technical skills, Analysis, Technical, Design, Soap, Agile, Updates, Programming, Java, Sdlc, Javascript, Xml, Coding, Html5, Jira, Html]                3.2                    [ React JS Software Developer, d React JS, , ]        NaN              4.0\n",
            "        PRAGNYA PATTNAIK Expertise           []                      None         None                     [10]                                                                                 [Js, Analytical, Ui, Consulting, System, Css, Mobile, Conversion, English, Technical skills, Technical, Ecommerce, Agile, Java, Banking, Javascript, Android, Hotel, Seo, Html5]                2.0                                                                []        NaN              8.0\n",
            "      HARIPRIYA BATTINA Experience [9908576950] haripriyabattini@gmai.com         None            [(SSC, 2012)]                                                                                                    [Js, Ui, Information technology, Css, System, Windows, Sql, Mysql, Technical, Gmail, Sql server, Agile, Programming, Java, Ubuntu, Javascript, Jira, Html, C]               None                               [ UI Developer Reactjs,  EDUCATION]        NaN                0\n",
            "                Naveen Sadhu Title           []                      None         None                       []                                                                                                                                                                              [Analytical, Html, Engineering, Css, Communication, Computer science, Sql, Testing]               None                                         [ Current Project Client]        NaN              8.0\n",
            "                 KAMALAKAR REDDY .           []                      None         None                       []                                                                  [Js, Ui, System, Css, Content, Data collection, Visual, Windows, Communication, English, Analysis, Design, Technical, Agile, Updates, Ubuntu, Javascript, Coding, Html5, Jira, Html, Photoshop]                3.0                                            [ Development,  MARCH]        NaN                0\n",
            "               MAREEDU LOKESH BABU           []                      None         None                       []     [Construction, Js, Analytical, Servers, Css, System, Inventory, Testing, Php, Visual, Website, Windows, Database, Mysql, Design, Technical, Accounting, Engineering, Programming, End user, Documentation, Sales, Javascript, Presentation, Profiling, Html]                2.0                                                                []        NaN              4.0\n",
            "                            204 ,           []                      None         None                       []                                                                                                    [Design, Js, Javascript, Architecture, Ui, Debugging, Crm, Healthcare, Customer service, Css, Communication, Updates, Programming, Html, Usability, Research]                3.0                                                                NA         NA               NA\n",
            "               Kotani Durga Prasad           []                      None         None                       [] [Queries, Js, Ui, Routing, Os, Mobile, Json, Visual, Website, Windows, Communication, English, Technical skills, Broadcast, Technical, Design, Marketing, Engineering, Moment, Brand, Programming, Usability, Javascript, Interactive, Coding, Seo, Html5, Html]                3.1                                                                []        NaN                0\n",
            "       Thirupathamma Balla SUMMARY           []                      None         None                       []                                                                                                                                                                                                  [Technical, Json, Analytical, Javascript, Programming, Testing]               None [ Object Oriented Programming,  Work Experience Technical Skills]        NaN                0\n",
            "               MAREEDU LOKESH BABU           []                      None         None                       []     [Construction, Js, Analytical, Servers, Css, System, Inventory, Testing, Php, Visual, Website, Windows, Database, Mysql, Design, Technical, Accounting, Engineering, Programming, End user, Documentation, Sales, Javascript, Presentation, Profiling, Html]                2.0                                                                []        NaN              4.0\n",
            "            Ui-Developer/ React JS           []                      None         None                       []                                               [Js, Github, Ui, Css, System, Json, Website, Architecture, Video, Scrum, Technical skills, Analysis, Technical, Design, Soap, Agile, Updates, Programming, Java, Sdlc, Javascript, Xml, Coding, Html5, Jira, Html]                3.2                    [ React JS Software Developer, d React JS, , ]        NaN              4.0\n",
            "                SHAIK ABDUL SHARUK           []  sharukabdul786@gmail.com         None                       []                                                                                                                                                                                                                          [Technical, Js, Github, Email, English]               None                                         [ Wipro Career Objective]        NaN                0\n",
            "               MD KHIZARUDDIN RAUF           []                      None  [1-06-1998]                     [10]                                                                                              [Design, Improvement, Js, Analytical, Javascript, Architecture, Ui, Debugging, Architectures, Workflows, Css, Coding, Communication, English, Pattern, Html, Mysql]               None                              [  Currently, :9 Months Internship]        NaN                0\n",
            "              Ranga Gaganam Having           []                      None         None                       []                                                                                                                  [Design, Sdlc, Software development life cycle, Js, Javascript, Ui, Presentation, Specifications, System, Communication, Html5, Html, Pharmacy]                1.0                                                                []        NaN              4.0\n",
            "             Pranish Sonone Career           []                      None         None                       []                                                                                                                  [Design, Technical, Ecommerce, Js, Javascript, Website, Ui, Reporting, Css, Reports, Communication, English, Html5, Technical skills, Analysis]                2.0                                                                []        NaN              8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save DataFrame to CSV file\n",
        "output_file = '/content/drive/MyDrive/Resumes.text/resumes_data.csv'\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(\"CSV file saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyBGC0URAZwi",
        "outputId": "bf05acf2-c686-47f2-dae2-753c564e400b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resume=pd.read_csv=\"/content/drive/MyDrive/Resumes.text/resumes_data.csv\""
      ],
      "metadata": {
        "id": "nN6U71ByBkeD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6wGqTY7HF1Wp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}